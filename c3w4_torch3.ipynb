{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import spacy\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.utils import resample\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import torch\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd \n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this notebook is to develop an LSTM model that accurately predicts which Tweets are about real disasters and which ones are not. Given a wide range of alternative approaches, logistic regression and SVC will be tried as well for benchmarking the LSTM approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_df = pd.read_csv(\"train.csv\")\n",
    "raw_test_df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 5)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          7613\n",
       "keyword      221\n",
       "location    3341\n",
       "text        7503\n",
       "target         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "keyword       61\n",
       "location    2533\n",
       "text           0\n",
       "target         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "del raw_train_df['keyword']\n",
    "del raw_train_df['location']\n",
    "del raw_train_df['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns 'id', 'location','keyword' were removed due to data sparcity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing for deep learning\n",
    "def text_cleaner(text):\n",
    "    text = text.lower() # convert to lowercase\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text) # remove punctuation and special characters\n",
    "    text = re.sub(r'\\s+', ' ', text) # remove extra whitespace\n",
    "    text = re.sub(r'https?://\\S+', '', text) # remove URLs\n",
    "    text = re.sub(r\"#\", \"\", text)\n",
    "    return text\n",
    "\n",
    "train_data = raw_train_df.where((pd.notnull(raw_train_df)),'')\n",
    "test_data = raw_test_df.where((pd.notnull(raw_test_df)),'')\n",
    "\n",
    "train_data['text'] = train_data['text'].apply(text_cleaner)\n",
    "test_data['text'] = test_data['text'].apply(text_cleaner)\n",
    "\n",
    "df_majority = train_data[train_data['target'] == 0]\n",
    "df_minority = train_data[train_data['target'] == 1]\n",
    "\n",
    "df_minority_upsampled = df_minority.sample(replace=True, n=len(df_majority), random_state=123)  # Upsample minority class\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])  # Combine majority class and upsampled minority class\n",
    "\n",
    "train_data = df_upsampled.sample(frac=1).reset_index(drop=True)  # Shuffle rows\n",
    "\n",
    "X, Y = train_data['text'], train_data['target']\n",
    "X_test= test_data['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8684/8684 [01:11<00:00, 122.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8684, 32, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3263/3263 [00:22<00:00, 142.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3263, 33, 300])\n",
      "torch.Size([6947, 32, 300]) torch.Size([1737, 32, 300]) torch.Size([3263, 33, 300])\n",
      "torch.Size([8684, 32, 300])\n",
      "(8684,)\n"
     ]
    }
   ],
   "source": [
    "# Embed Data for Deep Learning\n",
    "def embed(docs):\n",
    "    nlp = spacy.load('en_core_web_lg')\n",
    "    docs_tensor = []\n",
    "    pbar = tqdm.trange(docs.shape[0])\n",
    "    for t in pbar:\n",
    "        doc = nlp(docs[t])\n",
    "        sentence_embeddings = [token.vector for token in doc]\n",
    "        docs_tensor.append(sentence_embeddings)\n",
    "\n",
    "    docs_tensor = [torch.tensor(np.array(d)) for d in docs_tensor]\n",
    "    docs_tensor = pad_sequence(docs_tensor, batch_first=True)\n",
    "\n",
    "    print(docs_tensor.shape)\n",
    "    return docs_tensor\n",
    "\n",
    "X_tensor = embed(X)\n",
    "X_test_tensor = embed(X_test)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_tensor, Y, test_size=0.2, random_state= 3)\n",
    "\n",
    "Y_train = torch.from_numpy(Y_train.values)\n",
    "Y_val = torch.from_numpy(Y_val.values)\n",
    "train_dataset = TensorDataset(X_train, Y_train)\n",
    "\n",
    "# Create dataLoader\n",
    "batch_size = 50\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = TensorDataset(X_val, Y_val)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(X_test_tensor)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(X_train.shape, X_val.shape, X_test_tensor.shape)\n",
    "print(X_tensor.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code splits a dataset into training and validation sets then converts the target variable arrays from the training and validation splits into PyTorch tensors. It then wraps these tensors with their corresponding features into TensorDataset objects for training, validation, and testing. Lastly, it creates DataLoader instances for the training, validation, and test datasets, with a batch size of 50 and shuffling enabled, and prints the shapes of the training, validation, and test feature sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Benchmark Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm  import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report,confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Preprocessing for benchmarking\n",
    "stop_words=set(stopwords.words('english'))\n",
    "stemming=PorterStemmer()\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower() # 1. Convert to lower\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # 2. Remove special characters\n",
    "    tokens = word_tokenize(text) # 3. Split to words\n",
    "    tokens = [word for word in tokens if word not in stop_words] # 4. Remove stopwords\n",
    "    tokens = [word for word in tokens if not word.isdigit()] # 5. Remove numbers\n",
    "    tokens = [stemming.stem(word) for word in tokens] # 7. Apply Stemming\n",
    "    return ' '.join(tokens) # To return these single words back into one string\n",
    "\n",
    "train_df1_b = train_df1.copy()\n",
    "train_df1_b['cleaned_text'] = train_df1_b['text'].apply(clean_text)\n",
    "\n",
    "tf_idf=TfidfVectorizer()\n",
    "x_b = tf_idf.fit_transform(train_df1_b['cleaned_text'])\n",
    "y_b = train_df1_b['target']\n",
    "\n",
    "X_train_b,X_test_b,y_train_b,y_test_b = train_test_split(x_b,y_b,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7834\n",
      "Classification Report of SVC:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.93      0.83       841\n",
      "           1       0.88      0.59      0.71       664\n",
      "\n",
      "    accuracy                           0.78      1505\n",
      "   macro avg       0.81      0.76      0.77      1505\n",
      "weighted avg       0.80      0.78      0.77      1505\n",
      "\n",
      "Training accuracy: 0.9720744680851063\n",
      "Test accuracy: 0.7833887043189369\n",
      "Training Accuracy of SVC : 98.02\n",
      "Testing Accuracy  of  SVC: 79.14\n"
     ]
    }
   ],
   "source": [
    "# SVC benchmark model\n",
    "svc = SVC()\n",
    "svc.fit(X_train_b,y_train_b)\n",
    "svc_y_pred_b = svc.predict(X_test_b)\n",
    "accuracy = accuracy_score(y_test_b, svc_y_pred_b)\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(\"Classification Report of SVC:\\n\", classification_report(y_test_b, svc_y_pred_b))\n",
    "\n",
    "print('Training Accuracy Base SVC :', svc.score(X_train_b,y_train_b))\n",
    "print('Test Accuracy Base SVC :', svc.score(X_test_b,y_test_b))\n",
    "\n",
    "# SVC Hyperparameter tuning\n",
    "svc = SVC()\n",
    "param_grid={\n",
    "    'C':[0.001,0.01,0.1,1,10,],\n",
    "    'class_weight': [None, 'balanced']\n",
    "           }\n",
    "grid_search_svc = GridSearchCV(svc, param_grid,cv=5,scoring='accuracy')\n",
    "grid_search_svc.fit(X_train_b, y_train_b)\n",
    "best_model_svc = grid_search_svc.best_estimator_\n",
    "\n",
    "y_train_pred_svc=best_model_svc.predict(X_train_b)\n",
    "trainning_accuracy_svc=accuracy_score(y_train_b, y_train_pred_svc)\n",
    "\n",
    "y_test_pred_svc=best_model_svc.predict(X_test_b)\n",
    "testing_accuracy_svc=accuracy_score(y_test_b, y_test_pred_svc)\n",
    "\n",
    "print(f\"Training Accuracy Tuned SVC : {trainning_accuracy_svc * 100:.2f}\")\n",
    "print(f\"Testing Accuracy Tuned SVC : {testing_accuracy_svc * 100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7894\n",
      "Classification Report of Logistic Regression:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.93      0.83       841\n",
      "           1       0.87      0.62      0.72       664\n",
      "\n",
      "    accuracy                           0.79      1505\n",
      "   macro avg       0.81      0.77      0.78      1505\n",
      "weighted avg       0.80      0.79      0.78      1505\n",
      "\n",
      "Training Accuracy of Logistic Regression : 89.00\n",
      "Testing Accuracy  of Logistic Regression: 78.94\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression benchmark model\n",
    "log_r = LogisticRegression()\n",
    "log_r.fit(X_train_b,y_train_b)\n",
    "logr_y_pred_b = log_r.predict(X_test_b)\n",
    "accuracy = accuracy_score(y_test_b, logr_y_pred_b)\n",
    "print(f'Accuracy Base Logistic Regression: {accuracy:.4f}')\n",
    "print(\"Classification Report of Logistic Regression:\\n\", classification_report(y_test_b, logr_y_pred_b))\n",
    "\n",
    "# Hyperparameter tune the logistic regression model \n",
    "param_grid={'C':[0.001,0.01,0.1,1,10,100]}\n",
    "grid_search_lr = GridSearchCV(log_r, param_grid,cv=5,scoring='accuracy')\n",
    "grid_search_lr.fit(X_train_b,y_train_b)\n",
    "\n",
    "best_model_lr = grid_search_lr.best_estimator_\n",
    "y_train_pred_lr = best_model_lr.predict(X_train_b)\n",
    "trainning_accuracy_lr = accuracy_score(y_train_b, y_train_pred_lr)\n",
    "\n",
    "y_train_pred_lr = best_model_lr.predict(X_train_b)\n",
    "trainning_accuracy_lr = accuracy_score(y_train_b, y_train_pred_lr)\n",
    "\n",
    "y_test_pred_lr = best_model_lr.predict(X_test_b)\n",
    "testing_accuracy_lr = accuracy_score(y_test_b, y_test_pred_lr)\n",
    "\n",
    "print(f\"Training Accuracy Tuned Logistic Regression : {trainning_accuracy_lr * 100:.2f}\")\n",
    "print(f\"Testing Accuracy Tuned Logistic Regression: {testing_accuracy_lr * 100:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two benchmark models evaluated are Support Vector Classification (SVC) and Logistic Regression. The SVC model achieves a test accuracy of approximately 79.14%, with training accuracy of 98.02%. The Logistic Regression model shows a slightly lower test accuracy of 78.94% with a training accuracy of 89.00%. Overfitting is seen in both models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM and GRU Model Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes, dropout_prob=0.5):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.num_classes = num_classes\n",
    "        self.linear_i = nn.Linear(self.input_size, self.hidden_size)  # Linear layers for updating hidden state\n",
    "        self.linear_h = nn.Linear(self.input_size, self.hidden_size)  # Linear layers for updating hidden state\n",
    "        self.linear_f = nn.Linear(self.input_size, self.hidden_size)  # Linear layers for updating hidden state\n",
    "        self.fc = nn.Linear(self.hidden_size, self.num_classes) # Fully connected layer for classification\n",
    "        \n",
    "    def forward(self, x):\n",
    "        f = torch.sigmoid(self.linear_f(x))\n",
    "        i = torch.sigmoid(self.linear_i(x))\n",
    "        tilde_h = self.linear_h(x)\n",
    "        f_prime = f / (f + i)\n",
    "        i_prime = i / (f + i)\n",
    "        h_prev = torch.zeros((x.shape[0], self.hidden_size))\n",
    "        \n",
    "        for i in range(x.shape[1]):\n",
    "            f_prime_t = f_prime[:, i, :]\n",
    "            i_prime_t = i_prime[:, i, :]\n",
    "            tilde_h_t = tilde_h[:, i, :]\n",
    "            h_prev = f_prime_t * h_prev + i_prime_t * tilde_h_t # Update hidden state with dropout\n",
    "        out = self.fc(h_prev)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This LSTM model is a custom implementation that modifies the typical architecture of an LSTM by incorporating specific linear transformations for input and forget gates. The model takes inputs and applies linear layers to transform these inputs into hidden states, followed by sigmoid activation to compute the forget and input gate values, which control the information flow. Finally, the hidden states are passed through a fully connected layer to produce the model's output for classification purposes, effectively making it suitable for handling time-series or sequential data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(GRU, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(input_size, hidden_size,num_layers, dropout=0.2, batch_first = True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h_0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "        out, _ = self.gru(x, h_0)\n",
    "        out = out[:,-1,:]\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This GRU (Gated Recurrent Unit) model uses PyTorch's nn.GRU class for its core recurrent layer. The GRU layer is configured with a specific number of layers and a dropout rate to mitigate overfitting, processing the input sequences batch-wise. The output from the GRU layer is then fed into a fully connected linear layer that maps the hidden state to the desired number of output classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping():\n",
    "    def __init__(self, patience):\n",
    "        super(EarlyStopping, self).__init__()\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.last_acc = float(\"-inf\")\n",
    "        \n",
    "    def to_stop(self, acc):\n",
    "        if acc < self.last_acc:\n",
    "            if self.patience == self.counter:\n",
    "                return True\n",
    "            self.counter += 1\n",
    "        else:\n",
    "            self.counter = 0\n",
    "        self.last_acc = acc\n",
    "        return False "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Python class implements an early stopping mechanism to prevent overfitting. It is initialized with a 'patience' parameter, which specifies the number of epochs to continue training without improvement in accuracy before stopping. The to_stop method checks if the current accuracy (acc) is less than the last recorded accuracy; if it is, the counter is incremented and the method checks if it has reached the patience limit to decide whether to stop training. If the current accuracy improves, the counter is reset, encouraging continued training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training & Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_from_output(output):\n",
    "    category_index = torch.argmax(output).item()\n",
    "    return category_index\n",
    "\n",
    "def evaluate_model(model, val_dataloader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        for batch_X, batch_Y in val_dataloader:   # Zero the gradients\n",
    "            outputs = model(batch_X)  \n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            n_samples  += batch_Y.shape[0]\n",
    "            n_correct += (predictions == batch_Y).sum().item()\n",
    "        acc = 100* n_correct / n_samples\n",
    "        print(f'accuracy ={acc:.4f}')\n",
    "    model.train()\n",
    "    return acc\n",
    "\n",
    "def train(model, epoch, early_stopping, optimizer, criterion):\n",
    "    to_stop = False\n",
    "    for epoch in range(num_epochs):\n",
    "        iteration = 0\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        for batch_X, batch_Y in train_dataloader: # Zero the gradients\n",
    "            optimizer.zero_grad()  # Forward pass\n",
    "            output = model(batch_X)  # Compute loss\n",
    "            loss = criterion(output, batch_Y)\n",
    "\n",
    "            _, predictions = torch.max(output, 1)\n",
    "            n_samples  += batch_Y.shape[0]\n",
    "            n_correct += (predictions == batch_Y).sum().item()\n",
    "            acc = 100 * n_correct / n_samples\n",
    "\n",
    "            loss.backward() # Backward pass\n",
    "            optimizer.step()\n",
    "            iteration += 1\n",
    "            if iteration%100==0:\n",
    "                eval_acc = evaluate_model(model, val_dataloader)\n",
    "                if early_stopping.to_stop(eval_acc):\n",
    "                    to_stop = True\n",
    "                    break\n",
    "                print(f'Training accuracy ={acc:.4f}, Eval accuracy = {eval_acc:.4f}, {early_stopping.counter}')\n",
    "                print(f'epoch: {epoch+1}, step {iteration+1}, loss = {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The category_from_output function above extracts the category index from the model's output by identifying the maximum value's index, representing the predicted class. The evaluate_model function assesses the model's performance on the validation dataset by computing the accuracy as the percentage of correctly predicted instances and resets the model to training mode after evaluation. The train function orchestrates the training process over multiple epochs, handling forward and backward passes, loss computation, and updates to the model's weights through an optimizer; it also incorporates an early stopping mechanism that halts training if the validation accuracy does not improve over a specified number of iterations (patience parameter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy =50.3166\n",
      "Training accuracy =49.9800, Eval accuracy = 50.3166, 0\n",
      "epoch: 1, step 101, loss = 0.6875\n",
      "accuracy =50.3166\n",
      "Training accuracy =51.8400, Eval accuracy = 50.3166, 0\n",
      "epoch: 2, step 101, loss = 0.6946\n",
      "accuracy =51.5832\n",
      "Training accuracy =50.8000, Eval accuracy = 51.5832, 0\n",
      "epoch: 3, step 101, loss = 0.6854\n",
      "accuracy =51.9286\n",
      "Training accuracy =51.9200, Eval accuracy = 51.9286, 0\n",
      "epoch: 4, step 101, loss = 0.6844\n",
      "accuracy =52.1589\n",
      "Training accuracy =52.6000, Eval accuracy = 52.1589, 0\n",
      "epoch: 5, step 101, loss = 0.6716\n",
      "accuracy =53.5406\n",
      "Training accuracy =54.0000, Eval accuracy = 53.5406, 0\n",
      "epoch: 6, step 101, loss = 0.6797\n",
      "accuracy =53.5982\n",
      "Training accuracy =54.8600, Eval accuracy = 53.5982, 0\n",
      "epoch: 7, step 101, loss = 0.6665\n",
      "accuracy =70.5239\n",
      "Training accuracy =61.6200, Eval accuracy = 70.5239, 0\n",
      "epoch: 8, step 101, loss = 0.6661\n",
      "accuracy =76.1658\n",
      "Training accuracy =73.8000, Eval accuracy = 76.1658, 0\n",
      "epoch: 9, step 101, loss = 0.5458\n",
      "accuracy =78.1232\n",
      "Training accuracy =77.5400, Eval accuracy = 78.1232, 0\n",
      "epoch: 10, step 101, loss = 0.4717\n",
      "accuracy =79.7352\n",
      "Training accuracy =79.2600, Eval accuracy = 79.7352, 0\n",
      "epoch: 11, step 101, loss = 0.4754\n",
      "accuracy =81.2896\n",
      "Training accuracy =81.1400, Eval accuracy = 81.2896, 0\n",
      "epoch: 12, step 101, loss = 0.5267\n",
      "accuracy =81.1744\n",
      "Training accuracy =81.9200, Eval accuracy = 81.1744, 1\n",
      "epoch: 13, step 101, loss = 0.3959\n",
      "accuracy =80.8290\n",
      "Training accuracy =82.3200, Eval accuracy = 80.8290, 2\n",
      "epoch: 14, step 101, loss = 0.4141\n",
      "accuracy =81.0593\n",
      "Training accuracy =82.9200, Eval accuracy = 81.0593, 0\n",
      "epoch: 15, step 101, loss = 0.3082\n",
      "accuracy =82.4410\n",
      "Training accuracy =84.4400, Eval accuracy = 82.4410, 0\n",
      "epoch: 16, step 101, loss = 0.3810\n",
      "accuracy =82.4410\n",
      "Training accuracy =84.6200, Eval accuracy = 82.4410, 0\n",
      "epoch: 17, step 101, loss = 0.3037\n",
      "accuracy =81.8077\n",
      "Training accuracy =85.8200, Eval accuracy = 81.8077, 1\n",
      "epoch: 18, step 101, loss = 0.3302\n",
      "accuracy =82.0956\n",
      "Training accuracy =85.7400, Eval accuracy = 82.0956, 0\n",
      "epoch: 19, step 101, loss = 0.3731\n",
      "accuracy =82.6137\n",
      "Training accuracy =86.9000, Eval accuracy = 82.6137, 0\n",
      "epoch: 20, step 101, loss = 0.2725\n",
      "accuracy =82.7288\n",
      "Training accuracy =86.9400, Eval accuracy = 82.7288, 0\n",
      "epoch: 21, step 101, loss = 0.3110\n",
      "accuracy =82.9016\n",
      "Training accuracy =87.3800, Eval accuracy = 82.9016, 0\n",
      "epoch: 22, step 101, loss = 0.2823\n",
      "accuracy =83.2470\n",
      "Training accuracy =87.5400, Eval accuracy = 83.2470, 0\n",
      "epoch: 23, step 101, loss = 0.3600\n",
      "accuracy =83.1318\n",
      "Training accuracy =88.9800, Eval accuracy = 83.1318, 1\n",
      "epoch: 24, step 101, loss = 0.1885\n",
      "accuracy =83.0743\n",
      "Training accuracy =89.0600, Eval accuracy = 83.0743, 2\n",
      "epoch: 25, step 101, loss = 0.2058\n",
      "accuracy =83.8227\n",
      "Training accuracy =89.5400, Eval accuracy = 83.8227, 0\n",
      "epoch: 26, step 101, loss = 0.2663\n",
      "accuracy =83.8227\n",
      "Training accuracy =90.4000, Eval accuracy = 83.8227, 0\n",
      "epoch: 27, step 101, loss = 0.1815\n",
      "accuracy =83.7075\n",
      "Training accuracy =90.2600, Eval accuracy = 83.7075, 1\n",
      "epoch: 28, step 101, loss = 0.2188\n",
      "accuracy =83.8803\n",
      "Training accuracy =90.5000, Eval accuracy = 83.8803, 0\n",
      "epoch: 29, step 101, loss = 0.1630\n",
      "accuracy =84.1681\n",
      "Training accuracy =91.1200, Eval accuracy = 84.1681, 0\n",
      "epoch: 30, step 101, loss = 0.2053\n",
      "accuracy =84.2832\n",
      "Training accuracy =91.5200, Eval accuracy = 84.2832, 0\n",
      "epoch: 31, step 101, loss = 0.1164\n",
      "accuracy =83.9954\n",
      "Training accuracy =92.1000, Eval accuracy = 83.9954, 1\n",
      "epoch: 32, step 101, loss = 0.1728\n",
      "accuracy =84.4560\n",
      "Training accuracy =92.5600, Eval accuracy = 84.4560, 0\n",
      "epoch: 33, step 101, loss = 0.2277\n",
      "accuracy =84.8590\n",
      "Training accuracy =92.6000, Eval accuracy = 84.8590, 0\n",
      "epoch: 34, step 101, loss = 0.1276\n",
      "accuracy =84.4560\n",
      "Training accuracy =92.6200, Eval accuracy = 84.4560, 1\n",
      "epoch: 35, step 101, loss = 0.2626\n",
      "accuracy =84.4560\n",
      "Training accuracy =92.5400, Eval accuracy = 84.4560, 0\n",
      "epoch: 36, step 101, loss = 0.0884\n",
      "accuracy =84.5711\n",
      "Training accuracy =93.2800, Eval accuracy = 84.5711, 0\n",
      "epoch: 37, step 101, loss = 0.2347\n",
      "accuracy =84.8014\n",
      "Training accuracy =94.1000, Eval accuracy = 84.8014, 0\n",
      "epoch: 38, step 101, loss = 0.2863\n",
      "accuracy =85.0892\n",
      "Training accuracy =94.3800, Eval accuracy = 85.0892, 0\n",
      "epoch: 39, step 101, loss = 0.0955\n",
      "accuracy =84.8590\n",
      "Training accuracy =94.2000, Eval accuracy = 84.8590, 1\n",
      "epoch: 40, step 101, loss = 0.1120\n"
     ]
    }
   ],
   "source": [
    "# First Model - LSTM\n",
    "input_size = 300 # feed RNN one row at a time \n",
    "hidden_dims = 200\n",
    "\n",
    "n_categories = 2\n",
    "num_epochs = 40\n",
    "learning_rate = 0.001\n",
    "all_losses = []\n",
    "\n",
    "model = LSTM(input_size, hidden_dims, n_categories)\n",
    "early_stopping = EarlyStopping(2)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "train(model, num_epochs, early_stopping, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy =78.2959\n",
      "Training accuracy =68.5400, Eval accuracy = 78.2959, 0\n",
      "epoch: 1, step 101, loss = 0.5656\n",
      "accuracy =81.1744\n",
      "Training accuracy =81.1400, Eval accuracy = 81.1744, 0\n",
      "epoch: 2, step 101, loss = 0.4203\n",
      "accuracy =82.2683\n",
      "Training accuracy =83.3400, Eval accuracy = 82.2683, 0\n",
      "epoch: 3, step 101, loss = 0.4983\n",
      "accuracy =83.7651\n",
      "Training accuracy =85.4600, Eval accuracy = 83.7651, 0\n",
      "epoch: 4, step 101, loss = 0.3890\n",
      "accuracy =83.3621\n",
      "Training accuracy =87.3000, Eval accuracy = 83.3621, 1\n",
      "epoch: 5, step 101, loss = 0.1587\n",
      "accuracy =83.8803\n",
      "Training accuracy =89.4200, Eval accuracy = 83.8803, 0\n",
      "epoch: 6, step 101, loss = 0.2241\n",
      "accuracy =84.1681\n",
      "Training accuracy =91.3800, Eval accuracy = 84.1681, 0\n",
      "epoch: 7, step 101, loss = 0.1779\n",
      "accuracy =84.7438\n",
      "Training accuracy =92.5000, Eval accuracy = 84.7438, 0\n",
      "epoch: 8, step 101, loss = 0.2655\n",
      "accuracy =86.0679\n",
      "Training accuracy =93.5400, Eval accuracy = 86.0679, 0\n",
      "epoch: 9, step 101, loss = 0.0915\n",
      "accuracy =86.4134\n",
      "Training accuracy =95.0600, Eval accuracy = 86.4134, 0\n",
      "epoch: 10, step 101, loss = 0.2095\n"
     ]
    }
   ],
   "source": [
    "# Second Model - GRU\n",
    "num_epochs = 10\n",
    "early_stopping = EarlyStopping(2)\n",
    "n_hidden =2\n",
    "model1 = GRU(input_size, hidden_dims, n_hidden, n_categories)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model1.parameters(), lr=learning_rate)\n",
    "train(model1, num_epochs, early_stopping, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy =84.9165\n",
      "LSTM eval accuracy: 84.9165\n",
      "accuracy =87.5072\n",
      "GRU eval accuracy: 87.5072\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Both Models\n",
    "eval_acc = evaluate_model(model, val_dataloader)\n",
    "print(f'LSTM eval accuracy: {eval_acc:.4f}')\n",
    "\n",
    "eval_acc = evaluate_model(model1, val_dataloader)\n",
    "print(f'GRU eval accuracy: {eval_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model1(X_test_tensor)\n",
    "    _, predictions = torch.max(outputs, 1)\n",
    "submission = pd.DataFrame({'id': test_data['id'], 'target': predictions})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#dataframe of testing accruacy results\n",
    "data = {\n",
    "    'Model': ['GRU', 'LSTM', 'SVC', 'Logistic Regression'],\n",
    "    'Accuracy': [87.5072, 84.9165, 79.14, 78.94]\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "df_results = pd.DataFrame(data)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the style (optional)\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Create a bar chart\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(df_results['Model'], df_results['Accuracy'], color='blue')\n",
    "\n",
    "# Adding titles and labels\n",
    "plt.title('Testing Accuracy of Different Models')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GRU model outperformed the other models in terms of accuracy, with an accuracy of 87.5%. The LSTM model also performed well, with an accuracy of 84.9%. The benchmark models, SVC and Logistic Regression, had accuracies of 79.1% and 78.9%, respectively. The bar chart above shows the testing accuracy of the different models. \n",
    "\n",
    "Future work would include fine tuning the GRU model in general and to be able to handle larger batch sizes and thereby increase GPU utilization, which could increase accuracy further."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeponto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
